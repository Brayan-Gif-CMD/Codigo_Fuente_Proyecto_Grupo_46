Repositorio de Codigo Fuente del proyecto en GitHub.
Instruciones de ejecución:

1. Implementacion del conjunto de datos en Spark.
   - Ejecutar el codigo nano batch_processing.py
2. Realizar operaciones de limpieza, transformación y analisis exploratorio de datos (EDA), utilizando RDDs o DataFrames. Almacenando los resultados procesados.
   - Ejecutar el codigo eda_spark.py
3. Implementar la aplicacion Spark Streaming en un conjunto datos que consuma del topic de Kafka. Utilizar el script en Python usando PySpark para comsumir los datos de Kafka.
   - Ejecutar el codigo spark_kafka_streaming.py
4. Procesar los datos en tiempo real verificando los datos y visualizando los resultados del procesamiento.
   - Ejecutar el codigo procesamiento_streaming.py
